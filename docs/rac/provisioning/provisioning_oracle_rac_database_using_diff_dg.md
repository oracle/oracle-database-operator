#  Provisioning an Oracle RAC Database with differnet ASM disk groups for CRS and RDBMS

#### Use Case
* In this use case, the Oracle Grid Infrastructure and Oracle RAC Database are deployed automatically using Oracle RAC Controller. The responsefile is generated by the Oracle RAC Controller based on the input parameters specified in the .yaml file. 
* In this case, the Oracle RAC Database is deployed with with different diskgroups for CRS and RDBMS. 
* This example uses `racdb_prov_diff_dg_for_db_and_crs.yaml` to provision an Oracle RAC Database using Oracle RAC Controller. The provisioning includes:
  * 2 Kubernetes Pods as the RAC Nodes
  * Headless services for RAC
    * VIP Service
    * Scan Service
    * RAC Node hostname
  * Shared Persistent volumes created automatically based on specified shared disks for RAC shared storage(ASM)
  * Software Persistent Volumes and Staged Software Persistent Volumes using the specified location on the corresponding worker nodes
  * Namespace: `rac`
  * Staged Software location on the worker nodes is specified by `hostSwStageLocation`. Grid Infrastructure and RDBMS Binaries are copied to this location on the worker nodes. 
  * Software location on the worker nodes is specified by `racHostSwLocation`. The GI HOME and the RDBMS HOME in the Oracle RAC Pods will be mounted using this location on the corresponding worker node. 
  * Diskgroup named `CRSDATA` for the CRS 
  * Diskgroup named `DATA` for Database Files 
  * Diskgroup named `RECO` as the default location for fast recovery area 
  * Diskgroup named `REDO` for Oracle-managed control files and online redo logs 
  * Diskgroup named `OTHERDG` with type as `OTHERS` will have the disks available inside the pod for manual use (the diskgroup will actually not created) 


### In this example, 
  * A pre-built Oracle RAC Database slim image available on Oracle OCIR i.e. `phx.ocir.io/intsanjaysingh/db-repo/oracle/database-rac:19.3.0-slim` is used. 
  * If you plan to build the image yourself, you can build using the files from this [GitHub location](https://github.com/oracle/docker-images/tree/main/OracleDatabase/RAC/OracleRealApplicationClusters#building-oracle-rac-database-container-slim-image). In this case, you will need to change value of `image` with the image you have built in your enviornment in file `racdb_prov_diff_dg_for_db_and_crs.yaml`.   
  * The ASM diskgroup is configured using the shared disks on the worker nodes i.e. 
    * `/dev/disk/by-partlabel/qck-ocne19-asmdisk1` and `/dev/disk/by-partlabel/qck-ocne19-asmdisk2` for the `CRSDATA` diskgroup 
    * `/dev/disk/by-partlabel/qck-ocne19-asmdisk3` and `/dev/disk/by-partlabel/qck-ocne19-asmdisk4` for the `DATA` diskgroup 
    * `/dev/disk/by-partlabel/qck-ocne19-asmdisk5` and `/dev/disk/by-partlabel/qck-ocne19-asmdisk6` for the `RECO` diskgroup 
    * `/dev/disk/by-partlabel/qck-ocne19-asmdisk7` and `/dev/disk/by-partlabel/qck-ocne19-asmdisk8` for the `REDO` diskgroup 
    * `/dev/disk/by-partlabel/qck-ocne19-asmdisk9` and `/dev/disk/by-partlabel/qck-ocne19-asmdisk10` for any adhoc usage. They are specified under `OTHERDG` disk group and have type `OTHERS`. This diskgroup `OTHERDG` is a placeholder for these disks and will not be actually created. These disks will be mounted inside the RAC Database Pods. The end user can use these disks for any adhoc usage like backups or auxiliary storage needs. Redundancy is not specified for these disks. 
  * These disks are specified using parameter `asmDiskGroupDetails` in the YAML file.   


### Steps: Deploy 2 Node Oracle RAC Database with different diskgroups
Use the file: [racdb_prov_diff_dg_for_db_and_crs.yaml](./racdb_prov_diff_dg_for_db_and_crs.yaml) for this use case as below:

1. Deploy the `racdb_prov_diff_dg_for_db_and_crs.yaml` file:
    ```sh
    kubectl apply -f racdb_prov_diff_dg_for_db_and_crs.yaml
    ```
2. Check the status of the deployment:
    ```sh
    # Check the status of the Kubernetes Pods:    
    kubectl get all -n rac
    
    # Check the logs of a particular pod. For example, to check status of pod "racnode1-0":    
    kubectl exec -it pod/racnode1-0 -n rac -- bash -c "tail -f /tmp/orod/oracle_db_setup.log"
    ===================================
    ORACLE RAC DATABASE IS READY TO USE
    ===================================
    ```
3. Once the deployment is completed, check the details of the diskgroups:
    ```sh
    # Switch to one of the pod for RAC Nodes:    
    kubectl exec -it pod/racnode1-0 -n rac -- bash

    # Switch to the CRS user i.e. "grid"
    su - grid
    
    # Check the details of the diskgroups:
    [grid@racnode1-0 ~]$ asmcmd lsdg
    [grid@racnode1-0 ~]$ asmcmd lsdsk
    ```
4. Samples logs in [Logs](./logs/racdb_prov_diff_dg/racdbprov-sample_details.txt) and the corresponding [DB Operator Logs](./logs/racdb_prov_diff_dg/operator_logs.txt) when the above YAML file is applied.